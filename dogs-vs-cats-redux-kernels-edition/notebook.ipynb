{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Define root directory for data.\n",
    "This directory should already contain the test.zip and train.zip files from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"/home/gzpjpk/data/dogs-vs-cats-redux-kernels-edition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Unzip data downloaded from Kaggle into `test/` and `train/` folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!unzip $DATA_PATH/train.zip -d $DATA_PATH > /dev/null\n",
    "!unzip $DATA_PATH/test.zip -d $DATA_PATH > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir    $DATA_PATH/valid\n",
    "!mkdir    $DATA_PATH/results\n",
    "\n",
    "!mkdir -p $DATA_PATH/sample/train\n",
    "!mkdir    $DATA_PATH/sample/test\n",
    "!mkdir    $DATA_PATH/sample/valid\n",
    "!mkdir    $DATA_PATH/sample/results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Create validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = glob(DATA_PATH + '/train/*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for filepath in shuf[:2000]:\n",
    "    os.rename(filepath, DATA_PATH+'/valid/' + os.path.basename(filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Copy out some sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "\n",
    "def copyNFromTo(n, src, dest):\n",
    "    g = glob(src + '/*.jpg')\n",
    "    shuf = np.random.permutation(g)\n",
    "    for i in range(n):\n",
    "        filepath = shuf[i]\n",
    "        copyfile(filepath, dest + '/' + os.path.basename(filepath))\n",
    "\n",
    "        \n",
    "copyNFromTo(200, DATA_PATH+'/train', DATA_PATH+'/sample/train')\n",
    "copyNFromTo(50,  DATA_PATH+'/valid', DATA_PATH+'/sample/valid')\n",
    "copyNFromTo(50,  DATA_PATH+'/test',  DATA_PATH+'/sample/test' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Move cat and dog images into separate `dogs/` and `cats/` directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def separateDogsAndCats(dir):\n",
    "    !mkdir \"$dir/cats\"\n",
    "    !mkdir \"$dir/dogs\"\n",
    "    for filepath in glob(dir + '/*.jpg'):\n",
    "        filename = os.path.basename(filepath)\n",
    "        if (filename.startswith('cat')): \n",
    "            os.rename(filepath, dir + '/cats/' + filename)\n",
    "        elif (filename.startswith('dog')): \n",
    "            os.rename(filepath, dir + '/dogs/' + filename)\n",
    "        else:\n",
    "            raise Exception('Unexpected file: ' + filepath)\n",
    "                \n",
    "    \n",
    "separateDogsAndCats(DATA_PATH + '/sample/train')\n",
    "separateDogsAndCats(DATA_PATH + '/sample/valid')\n",
    "separateDogsAndCats(DATA_PATH + '/valid')\n",
    "separateDogsAndCats(DATA_PATH + '/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def moveToUnknown(base_path):\n",
    "    !mkdir $base_path/unknown\n",
    "    for filepath in glob(base_path+'/*.jpg'):\n",
    "        filename = os.path.basename(filepath)\n",
    "        os.rename(filepath, base_path + '/unknown/' + filename)\n",
    "\n",
    "moveToUnknown(DATA_PATH + '/test')\n",
    "moveToUnknown(DATA_PATH + '/sample/test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train VGG16 Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path = DATA_PATH + '/sample' # use sample data\n",
    "path = DATA_PATH # use real data\n",
    "\n",
    "vgg = Vgg16()\n",
    "batches = vgg.get_batches(path+'/train', batch_size=64)\n",
    "val_batches = vgg.get_batches(path+'/valid', batch_size=128)\n",
    "vgg.finetune(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "latest_weights_filename = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_of_epochs = 3\n",
    "\n",
    "for epoch in range(no_of_epochs):\n",
    "    print \"Running epoch: %d\" % epoch\n",
    "    vgg.fit(batches, val_batches, nb_epoch=1)\n",
    "    latest_weights_filename = 'ft%d.h5' % epoch\n",
    "    vgg.model.save_weights(DATA_PATH + '/results/' + latest_weights_filename) # saving weights after each epoch\n",
    "print \"Completed %s fit operations\" % no_of_epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "batches, preds = vgg.test(path+'/test', batch_size = batch_size*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the column ordering (appears that cats are column 1 and dogs are column 2) by viewing some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print preds[:5]\n",
    "print batches.filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "Image.open(path + '/test/' + batches.filenames[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save test results arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_array(path + '/results/test_preds.dat', preds)\n",
    "save_array(path + '/results/filenames.dat', batches.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaggle requires the following format for new submissions:\n",
    "\n",
    "```\n",
    "imageId,isDog\n",
    "1242, .3984\n",
    "3947, .1000\n",
    "4539, .9082\n",
    "2345, .0000\n",
    "```\n",
    "\n",
    "Log Loss is used to evalutate submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = load_array(path + '/results/test_preds.dat')\n",
    "filenames = load_array(path + '/results/filenames.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because log loss punishes confidently wrong answers more than it punishes confidently correct answers, tweak our results to be a bit less confident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Grab the dog prediction column\n",
    "original_pred_percent = preds[:,1]\n",
    "clipped_pred_percent = original_pred_percent.clip(min=0.05, max=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract imageIds from the filenames in our test/unknown directory \n",
    "ids = np.array([int(f[8:f.find('.')]) for f in batches.filenames])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we join the two columns into an array of [imageId, isDog]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = np.stack([ids, clipped_pred_percent], axis=1)\n",
    "subm[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission_file_path = path + '/submission.csv'\n",
    "np.savetxt(submission_file_path, subm, fmt='%d,%.5f', header='id,label', comments='')\n",
    "print submission_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
